{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Acquire the dataset\n",
    "\n",
    "We got the data from this google drive link. https://drive.google.com/drive/folders/16BK8_d1V-A3M1WQ0neaeCwqrHPfzH7QS?usp=sharing . This link is provided from Wei Shen where he gotten it from Mr.Afiq, who is the founder of Chili Lado.\n",
    "\n",
    "We decided not to use all the datasets in this google drive, however, we only selected the datasets that are relevant to our analysis. The selected the Product Overview datasets from the Product Folder. \n",
    "\n",
    "At first we downloaded all the dataset into our local drive by using the dowload all button.\n",
    "\n",
    "![DownloadAll](ChiliLadoData/DownloadAll.png)\n",
    "\n",
    "All the datasets is downloaded in this zipped file.\n",
    "\n",
    "![ZippedFile](ChiliLadoData/ZippedFile.png)\n",
    "![DownloadedFile](ChiliLadoData/DownloadedFile.png)\n",
    "\n",
    "Based on our observation, the zip include the Product Overview dataset which is from May 2023 to September 2023. All of them has 22 Column, however it has different number of rows. May, June, July, August, September has 32,31,32,32,31 rows respectively. The column names are:\n",
    "1. Date\n",
    "2. Product Visitors (Visit)\n",
    "3. Product Page Views\n",
    "4. Items Visited\n",
    "5. Product Bounce Visitors\n",
    "6. Product Bounce Rate\n",
    "7. Search Clicks\n",
    "8. Likes\n",
    "9. Product Visitors (Add to Cart)\n",
    "10. Units (Add to Cart)\n",
    "11. Conversion Rate (Add to Cart)\n",
    "12. Buyers (Placed Order)\n",
    "13. Units (Placed Order)\n",
    "14. Items Placed\n",
    "15. Sales (Placed Order)(MYR)\n",
    "16. Conversion Rate (Placed Order)\n",
    "17. Buyers (Confirmed Order)\n",
    "18. Units (Confirmed Order)\n",
    "19. Items Confirmed\n",
    "20. Sales (Confiremd Order)(MYR)\n",
    "21. Conversion Rate (Confirmed Order)\n",
    "22. Converison Rate (Placed to Confirmed)\n",
    "\n",
    "We first combine all the 5 files together, however we decided to do it with copy and paste instead of using python code because it only has 5 files. We use Ctrl+C to copy all the rows and use Ctrl+V to paste the copied rows into a new Excel File called MergedFile.xlsx.\n",
    "\n",
    "![CopiedFile](ChiliLadoData/CopiedFile.png)\n",
    "\n",
    "![PasteFile](ChiliLadoData/PasteFile.png)\n",
    "\n",
    "We copied all five datasets into the MergedFile. However, for May 2023, we copy the whole file including the column names, while for other months,we only copied the data. We pasted the data beneath May 2023. We followed the same process for July 2023 and subsequent months.\n",
    "\n",
    "![MayJune](ChiliLadoData/MayJune.png)\n",
    "\n",
    "To check if the data is merged correctly, we calculate the total number of rows by adding the number of days in these 5 months and the row contains attribute name which is 31 + 30 + 31 + 31 + + 30 + 1 = 154, as our MergedFile has 154 rows means that we had merged it correctly.\n",
    "\n",
    "Now the data can be used for the next few steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Import the dataset\n",
    "\n",
    "We import the dataset from our local directory. We created a file named ChiliLadoData and stored all the dataset and picture used there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('MergedFile.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Clean the data by dentifying and handling missing value, abnormality, outliers and redundancy\n",
    "\n",
    "Initially, almost all the data in the Excel file was not numerical data.\n",
    "\n",
    "![ConvertData](ChiliLadoData/ConvertData.png)\n",
    "\n",
    "Therefore, we converted all the data in the dataset into numerical values by selecting the \"Convert to Number\" option in Excel to prevent potential errors. You can identify non-numeric data when the left upper corner of the cell is marked in green.\n",
    "\n",
    "![Number](ChiliLadoData/Number.png)\n",
    "\n",
    "If all the cells are white, it indicates that we have successfully converted the data into numerical values. Now, we can proceed with using Python for data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the 'Date' column\n",
    "outliersdf = df.drop(columns=['Date'])\n",
    "\n",
    "# To check for outliers in the data\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.boxplot(data=outliersdf)\n",
    "plt.title(\"Boxplot of Data\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the first quartile (Q1), third quartile (Q3) and interquantile range (IQR)\n",
    "Q1 = outliersdf.quantile(0.25, numeric_only=True)\n",
    "Q3 = outliersdf.quantile(0.75, numeric_only=True)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identify and filter the outliers using the IQR method\n",
    "outlier_condition = ((outliersdf < (Q1 - 1.5 * IQR)) | (outliersdf > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# Dataframe with outliers are removed\n",
    "df = df[~outlier_condition]\n",
    "\n",
    "# Create a boxplot to visualize the cleaned DataFrame without outliers\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.boxplot(data=df)\n",
    "plt.title(\"Boxplot of Cleaned Data Without Outliers\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Display the cleaned data\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "\n",
    "# Remove unwanted data columns that are irrelevant to the analysis\n",
    "drop_columns = ['Product Bounce Visitors', 'Product Bounce Rate','Likes', 'Product Visitors (Add to Cart)',\n",
    "       'Units (Add to Cart)', 'Conversion Rate (Add to Cart)','Buyers (Placed Order)', 'Units (Placed Order)', 'Items Placed',\n",
    "       'Sales (Placed Order) (MYR)', 'Conversion Rate (Placed Order)','Buyers (Confirmed Order)', 'Units (Confirmed Order)',\n",
    "       'Items Confirmed','Conversion Rate (Confirmed Order)','Conversion Rate (Placed to Confirmed)']\n",
    "\n",
    "df1.drop(columns=drop_columns, inplace=True)\n",
    "\n",
    "display(df1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
